{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://thecleverprogrammer.com/2021/08/24/sarcasm-detection-with-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        article_link  \\\n",
      "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2  https://local.theonion.com/mom-starting-to-fea...   \n",
      "3  https://politics.theonion.com/boehner-just-wan...   \n",
      "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "\n",
      "                                            headline  is_sarcastic  \n",
      "0  former versace store clerk sues over secret 'b...             0  \n",
      "1  the 'roseanne' revival catches up to our thorn...             0  \n",
      "2  mom starting to fear son's web series closest ...             1  \n",
      "3  boehner just wants wife to listen, not come up...             1  \n",
      "4  j.k. rowling wishes snape happy birthday in th...             0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "data = pd.read_json(\"Sarcasm.txt\", lines=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The “is_sarcastic” column in this dataset contains the labels that we have to predict for the task of sarcasm detection. It contains binary values as 1 and 0, where 1 means sarcastic and 0 means not sarcastic. So for simplicity, I will transform the values of this column as “sarcastic” and “not sarcastic” instead of 1 and 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        article_link  \\\n",
      "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2  https://local.theonion.com/mom-starting-to-fea...   \n",
      "3  https://politics.theonion.com/boehner-just-wan...   \n",
      "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "\n",
      "                                            headline is_sarcastic  \n",
      "0  former versace store clerk sues over secret 'b...  Not Sarcasm  \n",
      "1  the 'roseanne' revival catches up to our thorn...  Not Sarcasm  \n",
      "2  mom starting to fear son's web series closest ...      Sarcasm  \n",
      "3  boehner just wants wife to listen, not come up...      Sarcasm  \n",
      "4  j.k. rowling wishes snape happy birthday in th...  Not Sarcasm  \n"
     ]
    }
   ],
   "source": [
    "data[\"is_sarcastic\"] = data[\"is_sarcastic\"].map({0: \"Not Sarcasm\", 1: \"Sarcasm\"})\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s prepare the data for training a machine learning model. This dataset has three columns, out of which we only need the “headline” column as a feature and the “is_sarcastic” column as a label. So let’s select these columns and split the data into 20% test set and 80% training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"headline\", \"is_sarcastic\"]]\n",
    "x = np.array(data[\"headline\"])\n",
    "y = np.array(data[\"is_sarcastic\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # Fit the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will be using the Bernoulli Naive Bayes algorithm to train a model for the task of sarcasm detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448146761512542\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text: Cows lose their jobs as milk prices drop\n",
      "['Sarcasm']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
